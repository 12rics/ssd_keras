{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras_ssd7 import build_model\n",
    "from keras_ssd_loss import SSD_Loss\n",
    "from ssd_box_encode_decode_utils import SSDBoxEncoder, decode_y\n",
    "from ssd_batch_generator import parse_CSV, generate_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Set up the model\n",
    "\n",
    "# 1: Set some necessary parameters\n",
    "\n",
    "img_height = 300 # Height of the input images\n",
    "img_width = 480 # Width of the input images\n",
    "img_channels = 3 # Number of color channels of the input images\n",
    "n_classes = 2 # Number of classes including the background class\n",
    "min_scale=0.1 # The scaling factor for the smallest anchor boxes\n",
    "max_scale=0.8 # The scaling factor for the largest anchor boxes\n",
    "scales=[0.08, 0.16, 0.32, 0.64] # An explicit list of anchor box scaling factors. If this is passed, it will override `min_scale` and `max_scale`.\n",
    "aspect_ratios=[0.5, 1, 2] # The list of aspect ratios for the anchor boxes\n",
    "two_boxes_for_ar1=True # Whether or not you want to generate two anchor boxes for aspect ratio 1\n",
    "limit_boxes=True # Whether or not you want to limit the boxes to lie entirely within the image boundaries\n",
    "\n",
    "# 2: Build the Keras model (and possibly load some trained weights)\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "# The output `classifier_sizes` is needed below to set up `SSDBoxEncoder`\n",
    "model, classifier_sizes = build_model(image_size=(img_height, img_width, img_channels),\n",
    "                                      n_classes=n_classes,\n",
    "                                      min_scale=min_scale,\n",
    "                                      max_scale=max_scale,\n",
    "                                      scales=scales,\n",
    "                                      aspect_ratios=aspect_ratios,\n",
    "                                      two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                                      limit_boxes=limit_boxes)\n",
    "#model.load_weights('./model_0_weights.h5')\n",
    "#model = load_model('./model_0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Set up training\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# 3: Instantiate an Adam optimizer and the SSD loss function and compile the model\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=5e-05)\n",
    "\n",
    "ssd_loss = SSD_Loss(neg_pos_ratio=3, n_neg_min=0, alpha=1.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)\n",
    "\n",
    "# 4: Instantiate an encoder that can encode ground truth labels into the format needed by the SSD loss function \n",
    "\n",
    "ssd_box_encoder = SSDBoxEncoder(img_height=img_height,\n",
    "                                img_width=img_width,\n",
    "                                n_classes=n_classes,\n",
    "                                classifier_sizes=classifier_sizes,\n",
    "                                min_scale=min_scale,\n",
    "                                max_scale=max_scale,\n",
    "                                scales=scales,\n",
    "                                aspect_ratios=aspect_ratios,\n",
    "                                two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "                                limit_boxes=limit_boxes,\n",
    "                                pos_iou_threshold=0.5,\n",
    "                                neg_iou_threshold=0.3,\n",
    "                                coords='centroids')\n",
    "\n",
    "# 5: Create the batch generator\n",
    "\n",
    "filenames, labels = parse_CSV('./data/labels.csv', n_classes)\n",
    "\n",
    "train_generator = generate_batch(filenames=filenames,\n",
    "                                 labels=labels,\n",
    "                                 path_prefix='./data/',\n",
    "                                 batch_size=batch_size,\n",
    "                                 train=True,\n",
    "                                 ssd_box_encoder=ssd_box_encoder,\n",
    "                                 crop=False,\n",
    "                                 resize=False,\n",
    "                                 gray=False,\n",
    "                                 equalize=False,\n",
    "                                 brightness=(0.5, 2, 0.7),\n",
    "                                 flip=0.5,\n",
    "                                 translate=((10, 200), (10, 150), 0.7),\n",
    "                                 scale=(0.75, 1.3, 0.7),\n",
    "                                 limit_boxes=True,\n",
    "                                 include_thresh=0.4,\n",
    "                                 diagnostics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Run training\n",
    "\n",
    "# 6: Run training\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "history = model.fit_generator(generator = train_generator,\n",
    "                              steps_per_epoch = int(len(filenames)/batch_size)+1,\n",
    "                              epochs = epochs,\n",
    "                              callbacks = [ModelCheckpoint('./model_0_weights_{epoch:02d}_{loss:.2f}.h5',\n",
    "                                                           monitor='loss',\n",
    "                                                           verbose=1,\n",
    "                                                           save_best_only=True,\n",
    "                                                           save_weights_only=True,\n",
    "                                                           mode='auto',\n",
    "                                                           period=1),\n",
    "                                           EarlyStopping(monitor='loss',\n",
    "                                                         min_delta=0.1,\n",
    "                                                         patience=5),\n",
    "                                           ReduceLROnPlateau(monitor='loss',\n",
    "                                                             factor=0.5,\n",
    "                                                             patience=3,\n",
    "                                                             epsilon=0.1,\n",
    "                                                             cooldown=0)])\n",
    "\n",
    "model_name = 'model_0'\n",
    "model.save('./{}.h5'.format(model_name))\n",
    "model.save_weights('./{}_weights.h5'.format(model_name))\n",
    "\n",
    "print()\n",
    "print(\"Model saved as {}.h5\".format(model_name))\n",
    "print(\"Weights also saved separately as {}_weights.h5\".format(model_name))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
